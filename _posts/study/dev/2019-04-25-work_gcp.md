---
title: "ForkJoin Framework와 Pub/Sub을 이용한 푸시발송 처리"
categories: "GCP"
tags:
  - GCP
  - pub/sub
  - BigQuery
toc: true
header:
  overlay_image: /assets/images/header/pattern.jpg
  overlay_filter: 0.5
  show_overlay_excerpt: false
---

# 들어가기

> 이 글은 [천만명의 사용자에게 1분내로 알림 보내기](https://taetaetae.github.io/2019/01/02/faster-parallel-processes/) 포스팅을 보고 흉내를 내봤습니다. 실력도 부족하고, 내용도 빈약하지만 비슷한 작업을 조금 다르게 처리했던 경험담을 가볍게 봐주시면 감사드리겠습니다.

필자는 사내에서 `푸시 서비스`와 `데이터 마이그레이션`(ETL)을 담당하고 있다.

그 중 최근 진행한 `푸시 서비스`의 고도화에 대한 이야기를 다룰까 한다.

최근 소셜커머스의 핵심은(사실 모든 서비스에 해당하지만) 사용자별 맞춤 서비스이다.

예를들어, 나는 30대 싱글남인데 '육아용품'과 관련된 광고성 푸시가 나에게 오면 관심이 없을 뿐만 아니라, 앱을 삭제해버릴지도 모른다.(성격 파탄자 아님)

그래서 우리 실에서는 **'사용자 별 맞춤 서비스'**를 위해 다양한 방법으로 서비스를 연구하고 제공한다.

---

본론으로 돌아와서, 현재 푸시 서비스는 문제없이 잘 작동하고 있다.

아니, 사실 문제가 있다.

![](/assets/images/study/dev/2019/themejoo/mysql_1.png)

> 태백산맥과 같이 요동치는 커넥션
{: .text-center}

![](/assets/images/study/dev/2019/themejoo/mysql_2.png)

> 커넥션보고 놀란 심장박동수 (feat. read/write & quries)
{: .text-center}

위 요동치는 그래프 패턴은 푸시발송의 **법적 준수시간 (오전 8시~ 오후9시까지)**에 알맞게 움직임을 보인다.

그렇다. 저 모든 그래프의 움직임은 푸시발송때마다 고생하는 우리 SQL서버의 모습이다!

이제 내가 할 일이 명확해 보인다.

> **Mission** : MySQL서버의 트래픽을 줄이고, 기존의 푸시 발송 속도(2분 안팎)을 유지하라!

---

## 요구사항 분석

개발에 앞서, 현재 상황을 짚어봐야 한다.

![](/assets/images/study/dev/2019/themejoo/push_process.png)

1. IDC서버에 있는 원본 푸시데이터를 일정 시간마다 ETL 한다.
2. ETL한 데이터는 우리가 사용하는 CloudSQL(MySQL)로 적재하고, 스케줄 정보를 Pub/Sub에 게시한다.
3. 게시된 스케줄은 Quartz Scheduler의 Job에 등록된다.
4. 해당 스케줄 시간이 되면 Quartz Shceduler의 Job이 실행된다.
5. 발송모듈은 스케줄 정보를 읽어서, 발송할 푸시 데이터에 맞게 가공한다.
6. 가공한 데이터는 다시 Pub/Sub을 통해 게시된다.
7. 구독(Subscription) 후 `FCM`을 통해 푸시가 발송된다.
8. 발송 결과를  `빅쿼리` && `ElsaticSearch` 에 저장한다.(후작업)

IDC서버를 거쳐 푸시 데이터가 세팅되기 때문에 다소 부자연스러운 과정이 있지만,

푸시를 발송하는 입장에서는 그저 CloudSQL(MySQL)에 저장된 푸시데이터를 빠짐없이 **잘**읽어서 푸시데이터로 가공하여 Pub/Sub에 전달해주면 된다.

70만건의 데이터를 2분만에 발송하는 것은 그리 어려운일이 아니다. (MySQL에서 읽어들여서 그냥 쭉 보내면 된다!)

그런데 푸시 발송과 현재 환경에 몇가지 제약조건이 있다.

- 푸시발송은 1회, 최대 1,000개의 토큰에 발송이 가능
- 서두에 언급했듯이 70만건 푸시의 내용이 동일할 수도, 동일하지 않을 수도 있다.
  - 이 말인즉슨, 동일한 내용일 경우 최대 1,000개씩 그룹핑해서 발송하면되지만, 내용이 다를 경우 최대 70만건을 각각 보내야 한다.

이 말을 풀어보자면, FCM 푸시 데이터는 기본적으로 다음의 Json 포맷을 따른다. (참고 : [FCM 메세지 정보](https://firebase.google.com/docs/cloud-messaging/concept-options?hl=ko))

즉, 저 포맷 중 `title` && `body` 그리고 `AOS` && `iOS` 사용자에 따라 구분이 필요하다.

뿐만아니라, 사내의 정책에 따라 사용자 트래킹을 위해 심어 놓은 특수한 코드값들이 별도로 존재하기 때문에, 이것 또한 그룹핑 되는 요소 중 하나로 분리된다.

결국 70만건의 푸시데이터가 모두 동일할리가 없고, 어떻게 그룹핑될지 미리 알 수 없다.

> 무슨 수를 쓰던지, 푸시를 최대한 빨리 사용자들에게 전달하면 된다.

## MySQL -> BigQuery

기본적으로 많은 커넥션과 사용량이 많은 SQL서버이기 때문에, 이렇게 일시적으로 많은 IO가 일어나는 서비스를 함께 담당하는 것은 부담스럽다.

따라서 `MySql`의 부하를 줄이기 위해서, 푸시 데이터는 `BigQuery`로 이관하는 것이 가장 큰 골자이다.

기존 ETL 모듈에서 MySQL로 보내던 것을 BigQuery로 보내주면 된다.

## 발송 로직

여기서부터 조금 고민할 부분이 생긴다.

기존 발송 로직은 다음과 같다.

1. MySQL에서 1,000개씩 로딩한다.
2. `Hash값`<sub>(발송 데이터+트래킹 코드+디바이스 종류)</sub>이 같은 데이터까지 검증하여 Publisher에 전달한다.(*Pub/Sub 게시*)
3. 1,000를 모두 검증하거나, 중간에 다른 Has룹값이 오면, 그 값 이후로 다시 1,000개를 로딩한다.
4. 반복

단순하다. 1,000개씩 갖고와서, Hash값이 동일하다면 같은 푸시 내용이므로 하나로 그룹핑 하면된다.(최대 1,000개 그룹핑)

이와 같은 방법으로 70만개를 순회하는데 2분 내외로 모든 발송이 완료된다.(후작업 제외)

## BigQuery로 이관 후 테스트

우선 발송로직을 조금 변경했다.

앞선 흐름과 거의 동일한 방법이지만, 기존 방법은 `sortNo`이라는 필드를 기준으로 순차적으로 가져 왔다면, 

변경된 로직은

- 전체 데이터의 hash값을 가져와 리스트에 담는다. (GROUP BY)
- 조건절에 해당 hash값을 추가해서 순회한다.(1,000개씩 쪼개서 가져온다.)

기존에 정렬되지 않은 sortNo이라는 순서에 따라 1,000개씩 갖고 온다는 것이 비효율적이라 생각이 들어,

애초에 조건절에 hash값을 기준으로 가져와서 1000개씩 나누어 처리하는 것이 좋을 것 같아 이와 같이 변경을 하여 테스트를 했다.

> 테스트 결과 정리 해서 추가하기

1차적인 문제는 푸시데이터는 때에따라 70만개의 데이터가 모두 다르거나, 모두 동일한 그룹일 수 있다.

모두 동일한 그룹이라면 700,000 / 1000 = **700**번 쿼리를 날려서 발송처리를 할 것이며, 최악의 경우(*이럴 경우는 거의 없겠지만*) 70만번의 쿼리를 전송할지도 모른다.

상상도하기 싫은 끔찍한 일이다.

그런데 그것보다 더 중요한 문제는,

빅쿼리는 NoSQL이다. RDB와 달리, NoSQL의 사용목적 자체가 다르다.

NoSQL의 특성상 쿼리의 요청 시간이 현저하게 차이가 난다.

이 말인 즉슨, 최대한 쿼리를 많이 요청하지 않는 것이 좋다는 것이다.

그래서 이번엔 한번에 1,000개씩 요청하는 것이 아니라, 10,000개씩 요청해봤다. (700번 -> 70번)

그리고 10,000개를 순회하며 hash값이 같은 그룹, 그리고 1,000개가 쌓일때마다 pub/sub에 게시될 수 있도록 프로그램상에서 처리를 했다.

그리고 속도를 비교해봤다.

> 테스트 속도 추가

1,000개씩 했을때와 비교하여 상당히 속도가 개선되었지만, 여전히 느리다.

목표는 2분이내에 발송이 끝나야 한다.

## 병렬 발송 처리

사실 푸시 발송은 단계별 순차적으로 발송할 이유가 없다.

가장 중요한 것은

- 누락되지 않는 것
- **중복 발송되지 않을 것(매우 중요)**

이 두가지만 충족하면된다.

그렇다면 순차적으로 발송을 처리할 것이 아니라, 스레드를 여러개 확보하여 **병렬 처리**를 하면된다.

일반적으로 병렬처리는 `ExecutorService` 인터페이스를 이용하여 많이 구현하는데,

Stream을 사용하며 병렬처리를 보다 쉽게 도와주는 프레임워크를 알게되었는데, 그것이 바로 `Fork Join Framework`이다.




[참고]
- https://www.popit.kr/java8-stream%EC%9D%98-parallel-%EC%B2%98%EB%A6%AC/
- https://hamait.tistory.com/612
- http://blog.naver.com/PostView.nhn?blogId=2feelus&logNo=220732310413