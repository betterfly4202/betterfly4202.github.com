---
title: "ForkJoin Framework와 Pub/Sub을 이용한 푸시발송 고도화(2)"
categories: "GCP"
tags:
  - GCP
  - pub/sub
  - BigQuery
toc: true
header:
  overlay_image: /assets/images/header/pattern.jpg
  overlay_filter: 0.5
  show_overlay_excerpt: false
---

> [ForkJoin Framework와 Pub/Sub을 이용한 푸시발송 고도화(1)](https://betterfly88.github.io/gcp/work_gcp_1/)

## MySQL -> BigQuery

기본적으로 많은 커넥션과 사용량이 많은 SQL서버이기 때문에, 이렇게 일시적으로 많은 IO가 일어나는 서비스를 함께 담당하는 것은 부담스럽다.

따라서 `MySql`의 부하를 줄이기 위해서, 푸시 데이터는 `BigQuery`로 이관하는 것이 가장 큰 골자이다.

기존 ETL 모듈에서 MySQL로 보내던 것을 BigQuery로 보내주면 된다.

## 발송 로직

여기서부터 조금 고민할 부분이 생긴다.

기존 발송 로직은 다음과 같다.

1. MySQL에서 1,000개씩 로딩한다. (1회 발송시 최대 1,000개 동시 발송 가능하기 때문)
2. `Hash값`<sub>(발송 데이터+트래킹 코드+디바이스 종류)</sub>이 같은 데이터까지 검증하여 Publisher에 전달한다.(*Pub/Sub 게시*)<br/>
   (Hash값이 같다는 것은 발송에 필요한 모든 값이 동일하다는 것이다. 따라서 동일한 포맷으로 세팅하고 사용자 토큰값만 세팅해주면된다.)
3. 1,000개를 모두 검증해서 중간에 다른 Hash값이 오면 세팅된 값을 푸시 발송하고, 그 값 이후로 다시 1,000개를 로딩한다.
4. 발송 후 결과를 MySQL, BigQuery, ElasticSearch 의 각각 필요한 데이터로 나누어 저장한다.
5. 반복

단순하다. 1,000개씩 갖고와서, Hash값이 동일하다면 같은 푸시 내용이므로 하나로 그룹핑 하면된다.(최대 1,000개 그룹핑)

이와 같은 방법으로 70만개를 순회하는데 2분 내외로 모든 발송이 완료된다.(후작업 제외)

## BigQuery로 이관 후 테스트

우선 발송로직을 조금 변경했다.

앞선 흐름과 거의 동일한 방법이지만, 기존 방법은 `sortNo`이라는 필드를 기준으로 순차적으로 가져 왔다면,

변경된 로직은

- 전체 데이터의 hash값을 가져와 리스트에 담는다. (GROUP BY)
- 조건절에 해당 hash값을 추가해서 순회한다.(1,000개씩 쪼개서 가져온다.)

우선 hash값을 그룹핑한 이유는 단순히 sortNo 필드를 기준으로 정렬할 경우 중간에 다른 hash값이 들어오면 또 다시 쿼리를 날려서 결과를 기다려야한다.

이렇게 쿼리를 요청하는 것이 비효율적이라 생각이 들어, hash값을 기준으로 하여 순회해서 테스트를 진행했다.

> 테스트 결과 정리 해서 추가하기

1차적인 문제는 푸시데이터는 때에따라 70만개의 데이터가 모두 다르거나, 모두 동일한 그룹일 수 있다.

모두 동일한 그룹이라면 700,000 / 1000 = **700**번 쿼리를 날려서 발송처리를 할 것이며, 최악의 경우(*이럴 경우는 거의 없겠지만*) 70만번의 쿼리를 전송할지도 모른다.

상상도하기 싫은 끔찍한 일이다.

그런데 그것보다 더 중요한 문제는,

빅쿼리는 NoSQL이다. 일반적인 SQL과 달리, NoSQL의 사용목적 자체가 다르다.

NoSQL의 특성상 쿼리의 요청 시간이 현저하게 차이가 난다.

이 말인 즉슨, 최대한 쿼리를 요청하지 않는 것이 좋다는 것이다.

그래서 이번엔 한번에 1,000개씩 요청하는 것이 아니라, 10,000개씩 요청해봤다. (70만건인 경우 700번 -> 70번)

그리고 10,000개를 순회하며 hash값이 같은 그룹, 그리고 1,000개가 쌓일때마다 pub/sub에 게시될 수 있도록 프로그램상에서 처리를 했다.

그리고 속도를 비교해봤다.

> 테스트 속도 추가

1,000개씩 했을때와 비교하여 상당히 속도가 개선되었지만, 여전히 느리다.

목표는 2분이내에 발송이 끝나야 한다.

## 병렬 발송 처리

사실 푸시 발송은 단계별 순차적으로 발송할 이유가 없다.

가장 중요한 것은

- 누락되지 않는 것
- **중복 발송되지 않을 것(매우 중요)**

이 두가지만 충족하면된다.

그렇다면 순차적으로 발송을 처리할 것이 아니라, 스레드를 여러개 확보하여 **병렬 처리**를 하면된다.

일반적으로 병렬처리는 `ExecutorService` 인터페이스를 이용하여 많이 구현하는데,

Stream을 사용하며 병렬처리를 보다 쉽게 도와주는 프레임워크를 알게되었는데, 그것이 바로 `Fork Join Framework`이다.




[참고]
- https://www.popit.kr/java8-stream%EC%9D%98-parallel-%EC%B2%98%EB%A6%AC/
- https://hamait.tistory.com/612
- http://blog.naver.com/PostView.nhn?blogId=2feelus&logNo=220732310413